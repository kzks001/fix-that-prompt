# ğŸ® Fix That Prompt!

An interactive game that challenges players to improve bad prompts using AI-powered evaluation and the COSTAR framework.

## ğŸ¯ What is Fix That Prompt?

**Fix That Prompt!** is a single-player game where multiple users take turns to improve bad prompts and compete for the highest RAGAS-based scores. Each player can play only once with a unique username, making every attempt count!

### ğŸ§© How the Game Works

1. **Enter a unique username** to start your game session
2. **Play up to 3 rounds** - each presenting:
   - A bad prompt with weak response
   - COSTAR framework guidance
   - Your chance to rewrite and improve the prompt
3. **Get scored** using LLM-as-a-judge evaluation (max 10 points)
4. **Compete** for a spot on the Top 10 leaderboard!

### ğŸ“Š Scoring System

- **Prompt Quality (0-5 points):** Clarity, specificity, and completeness
- **COSTAR Usage (0-3 points):** Adherence to the COSTAR framework
- **Creativity Bonus (0-2 points):** Innovation and unique approaches
- **Total:** Up to 10 points per round
- **Final Score:** Your best round score becomes your leaderboard score

### ğŸ® Game Features

#### Core Functionality
- âœ… Unique username enforcement
- âœ… Multi-round gameplay (up to 3 rounds)
- âœ… COSTAR framework guidance
- âœ… Real-time LLM-as-a-judge evaluation
- âœ… Interactive leaderboard
- âœ… Session persistence
- âœ… Comprehensive logging

#### Scoring & Evaluation
- âœ… Multi-criteria evaluation (Quality + COSTAR + Creativity)
- âœ… Detailed feedback for each submission
- âœ… Encouraging performance messages
- âœ… Best-score-wins final scoring

#### User Experience
- âœ… Intuitive Chainlit chat interface
- âœ… Clear game instructions and guidance
- âœ… Real-time feedback and scoring
- âœ… Top 10 leaderboard with rankings
- âœ… Session statistics and progress tracking

### ğŸ—ï¸ Architecture

The game is built with robust architecture following SOLID principles:

```
fix-that-prompt/
â”œâ”€â”€ data/                     # Game data and persistence
â”‚   â”œâ”€â”€ bad_prompts.json     # Prompt scenarios
â”‚   â””â”€â”€ leaderboard.json     # Player scores (auto-created)
â”œâ”€â”€ src/                     # Source code
â”‚   â”œâ”€â”€ components/          # Game logic and session management
â”‚   â”œâ”€â”€ database/           # Data persistence layer
â”‚   â”œâ”€â”€ evaluators/         # RAGAS scoring system
â”‚   â”œâ”€â”€ models/            # Data models and structures
â”‚   â”œâ”€â”€ prompts/           # Prompt loading utilities
â”‚   â””â”€â”€ utils/             # Logging and utilities
â”œâ”€â”€ logs/                   # Application logs (auto-created)
â”œâ”€â”€ main.py                # Application entry point
â””â”€â”€ pyproject.toml         # Project configuration
```

### ğŸ› ï¸ Tech Stack

- **UI Framework:** [Chainlit](https://docs.chainlit.io/) - Interactive chat interface
- **LLM Pipeline:** [LangChain](https://python.langchain.com/) - AI orchestration
- **Evaluation:** Custom LLM-as-a-judge scoring system
- **Logging:** [Loguru](https://loguru.readthedocs.io/) - Comprehensive logging
- **Data Storage:** DynamoDB (AWS) with JSON fallback (local development)